{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1ï¼šTF-IDF + Visualization - ASoIaF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this exercise is to analyze the A Song of Ice and Fire (ASoIaF) series by understanding the frequency and distribution of words across the corpus. A simple example is demonstrated by visualizing the bigrams with the top 10 TF-IDF weights in each book from the series, which shows us the key characters that appear in such.\n",
    "\n",
    "**-------------------------------------------------------SPOILER ALERT!-------------------------------------------------------**\n",
    "\n",
    "Among all books in the series, the bigram \"ned said\" has the highest TF-IDF weight, and it appears only in the first book's list of top 10 bigrams. By taking a closer look at the list, we can see that the character \"Ned\" is included in 3 out of the top 10 bigrams from *A Game of Thrones*. This matches the storyline, as the first of the series ended with the key character Eddard \"Ned\" Stark being executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Game of Thrones</td>\n",
       "      <td>./files/001ssb.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Clash of Kings</td>\n",
       "      <td>./files/002ssb.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Storm of Swords</td>\n",
       "      <td>./files/003ssb.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Feast of Crows</td>\n",
       "      <td>./files/004ssb.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Dance With Dragons</td>\n",
       "      <td>./files/005ssb.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Book            Filename\n",
       "0     A Game of Thrones  ./files/001ssb.txt\n",
       "1      A Clash of Kings  ./files/002ssb.txt\n",
       "2     A Storm of Swords  ./files/003ssb.txt\n",
       "3      A Feast of Crows  ./files/004ssb.txt\n",
       "4  A Dance With Dragons  ./files/005ssb.txt"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Book': [\"A Game of Thrones\", \"A Clash of Kings\", \"A Storm of Swords\", \"A Feast of Crows\", \"A Dance With Dragons\"], 'Filename': ['./files/001ssb.txt','./files/002ssb.txt','./files/003ssb.txt','./files/004ssb.txt','./files/005ssb.txt']}\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create list to store text\n",
    "text_list = []\n",
    "\n",
    "for filename in df['Filename']:\n",
    "    with open(filename) as file:\n",
    "        text = \"\".join(file.readlines()[1:])\n",
    "    text_list.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Clean Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean text and store to column \"Word\" in df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens_list = [word_tokenize(text) for text in text_list]\n",
    "# convert to lower case\n",
    "tokens_list = [[w.lower() for w in tokens] for tokens in tokens_list]\n",
    "# remove punctuation from each word\n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped_list = [[w.translate(table) for w in tokens] for tokens in tokens_list]\n",
    "# remove remaining tokens that are not alphabetic\n",
    "words_list = [[word for word in stripped if word.isalpha()] for stripped in stripped_list]\n",
    "# filter out stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words_list = [[w for w in words if not w in stop_words] for words in words_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for word_list in words_list:\n",
    "    word = ' '.join(word_list)\n",
    "    corpus.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Compute TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the TF-IDF weights of the top 10 bigrams (a 2-word term) for each book and save to csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigrams:\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "stopwords = ['chapter']\n",
    "vectorizer = TfidfVectorizer(min_df=2, max_df=.5, ngram_range=(2,2), stop_words = stopwords)\n",
    "tfidf = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------A Game of Thrones------------\n",
      "   TF-IDF weight               Term\n",
      "0       0.471123           ned said\n",
      "1       0.106234           ned told\n",
      "2       0.078520  littlefinger said\n",
      "3       0.069283        vayon poole\n",
      "4       0.064664           said ned\n",
      "5       0.064664        rodrik said\n",
      "6       0.060045    stallion mounts\n",
      "7       0.060045       mounts world\n",
      "8       0.050807          bran robb\n",
      "9       0.046189        jory cassel\n",
      "------------A Clash of Kings------------\n",
      "   TF-IDF weight              Term\n",
      "0       0.203817       ser cortnay\n",
      "1       0.161157       ser jacelyn\n",
      "2       0.123238       jaqen hghar\n",
      "3       0.113758   maester cressen\n",
      "4       0.109018       black betha\n",
      "5       0.090059     lady hornwood\n",
      "6       0.080579  thoren smallwood\n",
      "7       0.075839       lady selyse\n",
      "8       0.071099   cortnay penrose\n",
      "9       0.066359   jacelyn bywater\n",
      "------------A Storm of Swords------------\n",
      "   TF-IDF weight              Term\n",
      "0       0.115351  tom sevenstrings\n",
      "1       0.090633      yellow cloak\n",
      "2       0.074154         mo nakloz\n",
      "3       0.070035        kraznys mo\n",
      "4       0.061795    lem lemoncloak\n",
      "5       0.053556  thoren smallwood\n",
      "6       0.053556        said grenn\n",
      "7       0.049436     painted table\n",
      "8       0.049436        lord davos\n",
      "9       0.049436        said mance\n",
      "------------A Feast of Crows------------\n",
      "   TF-IDF weight               Term\n",
      "0       0.175894         kindly man\n",
      "1       0.158305  lady merryweather\n",
      "2       0.158305      ser creighton\n",
      "3       0.105537      cinnamon wind\n",
      "4       0.105537      high holiness\n",
      "5       0.096742      lady waynwood\n",
      "6       0.092344        lord rodrik\n",
      "7       0.083550          blue bard\n",
      "8       0.083550         ser lothor\n",
      "9       0.079152      water gardens\n",
      "------------A Dance With Dragons------------\n",
      "   TF-IDF weight            Term\n",
      "0       0.273822     lord ramsay\n",
      "1       0.207036        zo loraq\n",
      "2       0.187000      hizdahr zo\n",
      "3       0.150268        shy maid\n",
      "4       0.143590     green grace\n",
      "5       0.140250  golden company\n",
      "6       0.116875  jon connington\n",
      "7       0.113536       mo reznak\n",
      "8       0.110197       reznak mo\n",
      "9       0.100179      kindly man\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in range(len(corpus)):\n",
    "    weights = np.asarray(tfidf[i,].mean(axis=0)).ravel().tolist()\n",
    "    weights_df = pd.DataFrame({'Term': vectorizer.get_feature_names(), 'TF-IDF weight': weights})\n",
    "    weights_df = weights_df.sort_values(by='TF-IDF weight', ascending=False).head(10)\n",
    "    weights_df = weights_df.reset_index(drop=True)\n",
    "    print('------------' + df['Book'][i] + '------------')\n",
    "    print(weights_df)\n",
    "#    weights_df.to_csv(\"bigrams_\" + str(i+1) + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the bigrams with the top 10 TF-IDF weights for each book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type='text/javascript' src='https://us-west-2b.online.tableau.com/javascripts/api/viz_v1.js'></script><div class='tableauPlaceholder' style='width: 1000px; height: 1927px;'><object class='tableauViz' width='1000' height='1927' style='display:none;'><param name='host_url' value='https%3A%2F%2Fus-west-2b.online.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='&#47;t&#47;jessiecreates' /><param name='name' value='ASoIaFVisualization&#47;ASoIaF' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='showAppBanner' value='false' /><param name='filter' value='iframeSizedToWindow=true' /></object></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<script type='text/javascript' src='https://us-west-2b.online.tableau.com/javascripts/api/viz_v1.js'></script><div class='tableauPlaceholder' style='width: 1000px; height: 1927px;'><object class='tableauViz' width='1000' height='1927' style='display:none;'><param name='host_url' value='https%3A%2F%2Fus-west-2b.online.tableau.com%2F' /> <param name='embed_code_version' value='3' /> <param name='site_root' value='&#47;t&#47;jessiecreates' /><param name='name' value='ASoIaFVisualization&#47;ASoIaF' /><param name='tabs' value='no' /><param name='toolbar' value='yes' /><param name='showAppBanner' value='false' /><param name='filter' value='iframeSizedToWindow=true' /></object></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
